# GuardianEcho ğŸ”ŠğŸ›¡ï¸

*A real-time smart audio-classification engine that listens, understands, and reacts.*

GuardianEcho is an end-to-end **audio-event detection & alerting system**. Using a hybrid of **SVM classifiers** and **deep-learning models** (TensorFlow/Keras), it can distinguish between *speech, screams, shouts, noise* and other categories in real time, then trigger follow-up actions such as notifications, logging or UI cues.

---

## ğŸ“š Table of Contents

1. Features  
2. Architecture & File Map  
3. Branch & Version Strategy  
4. Installation  
5. Quick Start  
6. Usage Examples  
7. Contributing  
8. Roadmap  
9. License  

---

## âœ¨ Features

- **Real-time Audio Pipeline** â€“ streams microphone input, extracts MFCCs and passes them to the active model.  
- **Dual-Model Support** â€“ choose between fast classical SVMs (`svm_based_model/`) or a Keras CNN (`sound_classifier_nueral.py`).  
- **Dataset Builder** â€“ `datasetmaker.py` lets you curate and label custom WAV datasets.  
- **Extensible UI** â€“ lightweight **Kivy** front-end (`ui.kv`, `main.py`) with live predictions and alert pop-ups.  
- **Configurable Alerts** â€“ trigger sounds, desktop notifications or custom hooks on defined events.  
- **Plug-in Friendly** â€“ drop in a new `saved_model.pb` or additional SVM phases without touching the core logic.  

---

## ğŸ—‚ï¸ Architecture & File Map

```text
GuardianEcho/
â”œâ”€â”€ bin/                     # Virtual-env executables (local dev only)
â”œâ”€â”€ config/                  # Log files & runtime configs
â”œâ”€â”€ resources/
â”‚   â””â”€â”€ icons/               # UI icon assets
â”œâ”€â”€ svm_based_model/         # Classical SVM classifiers & CSV helpers
â”œâ”€â”€ testing/                 # Sample audio clips for smoke-tests
â”œâ”€â”€ variables/               # Runtime variable storage (pickle / json)
â”‚
â”œâ”€â”€ main.py                  # Kivy entry-point â€“ launches the GUI
â”œâ”€â”€ sound_classifier_nueral.py # CNN-based TF model & inference loop
â”œâ”€â”€ modelloader.py           # Wrapper to load *.pb SavedModels
â”œâ”€â”€ datasetmaker.py          # Command-line dataset creator
â”œâ”€â”€ sound.py                 # Cross-platform audio recording helper
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ LICENSE                  # MIT License
```

> **Tip:** See `how_to_use.txt` for a one-page overview.

---

## ğŸŒ³ Branch & Version Strategy

| Branch        | Status     | Purpose                                       |
|---------------|------------|-----------------------------------------------|
| `main`        | âœ… Stable   | Production-ready code. All PRs merge here.    |
| `feature/*`   | ğŸ› ï¸ Active  | For features, bug-fixes or refactors.         |
| `release/*`   | ğŸš€ Release | Tagged snapshots for versioned builds.        |

---

## ğŸ› ï¸ Installation

```bash
# 1. Clone the repo
git clone https://github.com/Adityarajsingh2904/GuardianEcho.git
cd GuardianEcho

# 2. (Optional) create a virtual environment
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Install Python dependencies
pip install -r requirements.txt
```

> **Note:** TensorFlow and Kivy may require additional system packages.

---

## âš¡ Quick Start

```bash
# Run the GUI application
python main.py

# Directly classify a WAV file
python sound_classifier_nueral.py --file path/to/clip.wav
```

---

## ğŸ–¥ï¸ Usage Examples

### 1. Train a New SVM Phase
```bash
python svm_based_model/phase1_speech_vs_noise.py --data /path/to/dataset
```

### 2. Batch-predict WAVs in a folder
```bash
python sound_classifier_nueral.py --folder ./testing --export ./results.csv
```

---

## ğŸ¤ Contributing

1. Fork the repo and create your branch:
```bash
git checkout -b feature/your-feature-name
```
2. Commit your changes and push.
3. Open a Pull Request.

---

## ğŸ—ºï¸ Roadmap

- [ ] Add Voice Activity Detection (VAD) pre-filter  
- [ ] Docker support for containerized deployment  
- [ ] REST API wrapper using FastAPI  
- [ ] Mobile-friendly UI adjustments

---

## ğŸ“„ License

Distributed under the **MIT License**. See `LICENSE` for more information.

---

> Made with â¤ï¸ by **Aditya Raj Singh** â€“ drop a â­ if you like the project!